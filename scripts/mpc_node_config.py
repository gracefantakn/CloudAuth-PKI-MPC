"""
Configuration et gestion d'un n≈ìud MPC sans HSM physique
Simulation s√©curis√©e des op√©rations cryptographiques distribu√©es
"""

import asyncio
import json
import time
import secrets
import hashlib
from typing import Dict, List, Optional, Tuple, Any, Set
from dataclasses import dataclass, field
from enum import Enum
import threading
from collections import defaultdict
import os
from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes
from cryptography.hazmat.primitives import hashes, hmac
from cryptography.hazmat.backends import default_backend

class MPCNodeState(Enum):
    """√âtats possibles d'un n≈ìud MPC"""
    INITIALIZING = "initializing"
    READY = "ready"
    PARTICIPATING = "participating"
    RECOVERING = "recovering"
    OFFLINE = "offline"
    COMPROMISED = "compromised"

class OperationType(Enum):
    """Types d'op√©rations MPC support√©es"""
    DKG = "distributed_key_generation"
    TSS_SIGNING = "threshold_signature_scheme"
    KEY_REFRESH = "key_refresh"
    PARTIAL_VERIFY = "partial_verification"
    EMERGENCY_RECOVERY = "emergency_recovery"

@dataclass
class SecretShare:
    """Part de secret s√©curis√©e"""
    share_id: str
    participant_id: int
    share_value: bytes  # Chiffr√©
    metadata: Dict[str, Any]
    created_at: float
    last_used: float = 0.0
    use_count: int = 0
    
@dataclass
class MPCOperation:
    """Op√©ration MPC en cours"""
    operation_id: str
    operation_type: OperationType
    participants: Set[int]
    threshold: int
    status: str
    created_at: float
    timeout: float
    parameters: Dict[str, Any] = field(default_factory=dict)
    contributions: Dict[int, Any] = field(default_factory=dict)
    result: Optional[Any] = None

@dataclass
class NodeSecurityConfig:
    """Configuration de s√©curit√© du n≈ìud"""
    encryption_key: bytes
    hmac_key: bytes
    node_identity: bytes
    attestation_enabled: bool = True
    auto_key_rotation: bool = True
    key_rotation_interval: int = 86400  # 24h
    max_operations_per_hour: int = 1000
    secure_deletion_passes: int = 3

class MPCSecureStorage:
    """
    Stockage s√©curis√© simul√© pour les parts de cl√©s
    Remplace le HSM physique avec chiffrement logiciel
    """
    
    def __init__(self, node_id: int):
        self.node_id = node_id
        self.storage_key = self._derive_storage_key()
        self.shares: Dict[str, SecretShare] = {}
        self.access_log: List[Dict] = []
        self.integrity_hashes: Dict[str, str] = {}
        
    def _derive_storage_key(self) -> bytes:
        """D√©rive une cl√© de stockage unique par n≈ìud"""
        # En production, utiliser un KDF avec salt unique
        seed = f"mpc_node_{self.node_id}_storage_key".encode()
        return hashlib.pbkdf2_hmac('sha256', seed, b'salt_demo', 100000)
    
    def store_share(self, share: SecretShare) -> bool:
        """Stocke une part de secret de mani√®re s√©curis√©e"""
        try:
            # Chiffrement de la part
            encrypted_share = self._encrypt_share_value(share.share_value)
            
            # Cr√©ation de la copie chiffr√©e
            encrypted_share_obj = SecretShare(
                share_id=share.share_id,
                participant_id=share.participant_id,
                share_value=encrypted_share,
                metadata=share.metadata,
                created_at=share.created_at
            )
            
            # Calcul du hash d'int√©grit√©
            integrity_data = f"{share.share_id}:{encrypted_share.hex()}:{share.created_at}"
            integrity_hash = hashlib.sha256(integrity_data.encode()).hexdigest()
            
            # Stockage
            self.shares[share.share_id] = encrypted_share_obj
            self.integrity_hashes[share.share_id] = integrity_hash
            
            # Log d'acc√®s
            self._log_access("STORE", share.share_id, True)
            
            print(f"üîí Part stock√©e: {share.share_id} (N≈ìud {self.node_id})")
            return True
            
        except Exception as e:
            self._log_access("STORE", share.share_id, False, str(e))
            print(f"‚ùå Erreur stockage part: {e}")
            return False
    
    def retrieve_share(self, share_id: str) -> Optional[SecretShare]:
        """R√©cup√®re et d√©chiffre une part de secret"""
        try:
            if share_id not in self.shares:
                self._log_access("RETRIEVE", share_id, False, "Share not found")
                return None
            
            # V√©rification d'int√©grit√©
            if not self._verify_integrity(share_id):
                self._log_access("RETRIEVE", share_id, False, "Integrity check failed")
                return None
            
            encrypted_share = self.shares[share_id]
            
            # D√©chiffrement
            decrypted_value = self._decrypt_share_value(encrypted_share.share_value)
            
            # Reconstruction de la part d√©chiffr√©e
            decrypted_share = SecretShare(
                share_id=encrypted_share.share_id,
                participant_id=encrypted_share.participant_id,
                share_value=decrypted_value,
                metadata=encrypted_share.metadata,
                created_at=encrypted_share.created_at,
                last_used=time.time(),
                use_count=encrypted_share.use_count + 1
            )
            
            # Mise √† jour des m√©tadonn√©es
            encrypted_share.last_used = decrypted_share.last_used
            encrypted_share.use_count = decrypted_share.use_count
            
            self._log_access("RETRIEVE", share_id, True)
            
            return decrypted_share
            
        except Exception as e:
            self._log_access("RETRIEVE", share_id, False, str(e))
            print(f"‚ùå Erreur r√©cup√©ration part: {e}")
            return None
    
    def _encrypt_share_value(self, share_value: bytes) -> bytes:
        """Chiffre une valeur de part"""
        # AES-256-GCM
        iv = secrets.token_bytes(12)  # 96 bits pour GCM
        cipher = Cipher(algorithms.AES(self.storage_key), modes.GCM(iv), backend=default_backend())
        encryptor = cipher.encryptor()
        
        ciphertext = encryptor.update(share_value) + encryptor.finalize()
        
        # Concat√©nation: IV + Tag + Ciphertext
        return iv + encryptor.tag + ciphertext
    
    def _decrypt_share_value(self, encrypted_data: bytes) -> bytes:
        """D√©chiffre une valeur de part"""
        iv = encrypted_data[:12]
        tag = encrypted_data[12:28]
        ciphertext = encrypted_data[28:]
        
        cipher = Cipher(algorithms.AES(self.storage_key), modes.GCM(iv, tag), backend=default_backend())
        decryptor = cipher.decryptor()
        
        return decryptor.update(ciphertext) + decryptor.finalize()
    
    def _verify_integrity(self, share_id: str) -> bool:
        """V√©rifie l'int√©grit√© d'une part stock√©e"""
        if share_id not in self.integrity_hashes:
            return False
        
        share = self.shares[share_id]
        integrity_data = f"{share.share_id}:{share.share_value.hex()}:{share.created_at}"
        computed_hash = hashlib.sha256(integrity_data.encode()).hexdigest()
        
        return computed_hash == self.integrity_hashes[share_id]
    
    def _log_access(self, operation: str, share_id: str, success: bool, error: str = None):
        """Enregistre un acc√®s aux parts"""
        log_entry = {
            "timestamp": time.time(),
            "operation": operation,
            "share_id": share_id,
            "success": success,
            "error": error,
            "node_id": self.node_id
        }
        self.access_log.append(log_entry)
        
        # Limitation de la taille du log
        if len(self.access_log) > 1000:
            self.access_log = self.access_log[-500:]
    
    def secure_delete_share(self, share_id: str) -> bool:
        """Suppression s√©curis√©e d'une part"""
        if share_id not in self.shares:
            return False
        
        try:
            # √âcrasement s√©curis√© (simulation)
            share = self.shares[share_id]
            for _ in range(3):  # 3 passes d'√©crasement
                share.share_value = secrets.token_bytes(len(share.share_value))
            
            # Suppression d√©finitive
            del self.shares[share_id]
            del self.integrity_hashes[share_id]
            
            self._log_access("DELETE", share_id, True)
            print(f"üóëÔ∏è  Part supprim√©e de mani√®re s√©curis√©e: {share_id}")
            
            return True
            
        except Exception as e:
            self._log_access("DELETE", share_id, False, str(e))
            return False

class MPCNode:
    """
    N≈ìud MPC avec simulation de s√©curit√© mat√©rielle
    Remplace les fonctionnalit√©s HSM par des impl√©mentations logicielles s√©curis√©es
    """
    
    def __init__(self, node_id: int, total_nodes: int, threshold: int):
        self.node_id = node_id
        self.total_nodes = total_nodes
        self.threshold = threshold
        self.state = MPCNodeState.INITIALIZING
        
        # Configuration de s√©curit√©
        self.security_config = self._initialize_security_config()
        
        # Stockage s√©curis√©
        self.secure_storage = MPCSecureStorage(node_id)
        
        # Op√©rations en cours
        self.active_operations: Dict[str, MPCOperation] = {}
        self.operation_history: List[str] = []
        
        # Interfaces r√©seau et consensus
        self.network_interface: Optional[Any] = None
        self.consensus_interface: Optional[Any] = None
        self.zkp_interface: Optional[Any] = None
        
        # M√©triques et monitoring
        self.metrics = {
            "operations_completed": 0,
            "operations_failed": 0,
            "signatures_generated": 0,
            "keys_generated": 0,
            "uptime_start": time.time(),
            "last_heartbeat": time.time()
        }
        
        # S√©curit√© op√©rationnelle
        self.rate_limiter = defaultdict(list)  # Anti-DoS
        self.trusted_peers: Set[int] = set(range(total_nodes)) - {node_id}
        self.session_keys: Dict[int, bytes] = {}
        
        print(f"üü¢ N≈ìud MPC {node_id} initialis√© (seuil: {threshold}/{total_nodes})")
    
    def _initialize_security_config(self) -> NodeSecurityConfig:
        """Initialise la configuration de s√©curit√©"""
        # G√©n√©ration de cl√©s cryptographiques fortes
        encryption_key = secrets.token_bytes(32)  # AES-256
        hmac_key = secrets.token_bytes(32)        # HMAC-SHA256
        node_identity = hashlib.sha256(f"mpc_node_{self.node_id}".encode()).digest()
        
        return NodeSecurityConfig(
            encryption_key=encryption_key,
            hmac_key=hmac_key,
            node_identity=node_identity,
            attestation_enabled=True,
            auto_key_rotation=True
        )
    
    async def start_node(self):
        """D√©marre le n≈ìud MPC"""
        print(f"üöÄ D√©marrage n≈ìud MPC {self.node_id}")
        
        self.state = MPCNodeState.READY
        
        # D√©marrage des t√¢ches de surveillance
        heartbeat_task = asyncio.create_task(self._heartbeat_routine())
        security_task = asyncio.create_task(self._security_monitoring())
        cleanup_task = asyncio.create_task(self._cleanup_routine())
        
        await asyncio.gather(heartbeat_task, security_task, cleanup_task)
    
    async def participate_in_dkg(self, operation_id: str, participants: List[int]) -> bool:
        """
        Participe √† une g√©n√©ration de cl√© distribu√©e
        """
        if len(participants) < self.threshold:
            print(f"‚ùå Pas assez de participants pour DKG: {len(participants)} < {self.threshold}")
            return False
        
        if self.node_id not in participants:
            print(f"‚ùå N≈ìud {self.node_id} non inclus dans les participants DKG")
            return False
        
        print(f"üîë N≈ìud {self.node_id}: Participation DKG {operation_id}")
        
        try:
            # Cr√©ation de l'op√©ration MPC
            operation = MPCOperation(
                operation_id=operation_id,
                operation_type=OperationType.DKG,
                participants=set(participants),
                threshold=self.threshold,
                status="in_progress",
                created_at=time.time(),
                timeout=300.0  # 5 minutes
            )
            
            self.active_operations[operation_id] = operation
            self.state = MPCNodeState.PARTICIPATING
            
            # Phase 1: G√©n√©ration du polyn√¥me secret local
            local_polynomial = self._generate_secret_polynomial()
            
            # Phase 2: Calcul des parts pour les autres participants
            shares_to_distribute = {}
            for participant_id in participants:
                if participant_id != self.node_id:
                    share_value = self._evaluate_polynomial(local_polynomial, participant_id)
                    shares_to_distribute[participant_id] = share_value
            
            # Phase 3: Distribution s√©curis√©e des parts
            await self._distribute_shares_securely(operation_id, shares_to_distribute)
            
            # Phase 4: Collecte des parts des autres participants
            await self._collect_dkg_shares(operation_id, participants)
            
            # Phase 5: Validation et finalisation
            final_share = await self._finalize_dkg(operation_id, local_polynomial[0])
            
            if final_share:
                # Stockage s√©curis√© de la part finale
                share_obj = SecretShare(
                    share_id=f"dkg_{operation_id}_{self.node_id}",
                    participant_id=self.node_id,
                    share_value=final_share,
                    metadata={
                        "operation_id": operation_id,
                        "participants": list(participants),
                        "threshold": self.threshold,
                        "key_type": "secp256k1"
                    },
                    created_at=time.time()
                )
                
                success = self.secure_storage.store_share(share_obj)
                
                if success:
                    operation.status = "completed"
                    operation.result = {"share_id": share_obj.share_id}
                    self.metrics["keys_generated"] += 1
                    self.metrics["operations_completed"] += 1
                    
                    print(f"‚úÖ DKG termin√©: {operation_id}")
                    return True
            
            # √âchec
            operation.status = "failed"
            self.metrics["operations_failed"] += 1
            return False
            
        except Exception as e:
            print(f"‚ùå Erreur DKG: {e}")
            if operation_id in self.active_operations:
                self.active_operations[operation_id].status = "failed"
            self.metrics["operations_failed"] += 1
            return False
        
        finally:
            self.state = MPCNodeState.READY
            # Nettoyage des donn√©es temporaires
            await self._cleanup_operation_data(operation_id)
    
    def _generate_secret_polynomial(self) -> List[int]:
        """G√©n√®re un polyn√¥me secret al√©atoire"""
        field_order = 2**256 - 2**32 - 977  # Ordre du corps pour secp256k1
        
        polynomial = []
        for i in range(self.threshold):
            coeff = secrets.randbelow(field_order)
            polynomial.append(coeff)
        
        return polynomial
    
    def _evaluate_polynomial(self, polynomial: List[int], x: int) -> bytes:
        """√âvalue le polyn√¥me en x et retourne le r√©sultat chiffr√©"""
        field_order = 2**256 - 2**32 - 977
        
        result = 0
        for i, coeff in enumerate(polynomial):
            result = (result + coeff * pow(x, i, field_order)) % field_order
        
        # Conversion en bytes s√©curis√©s
        return result.to_bytes(32, 'big')
    
    async def _distribute_shares_securely(self, operation_id: str, shares: Dict[int, bytes]):
        """Distribue les parts de mani√®re s√©curis√©e aux autres n≈ìuds"""
        # Simulation de la distribution chiffr√©e
        for participant_id, share_value in shares.items():
            # En production, chiffrement avec la cl√© publique du destinataire
            encrypted_share = self._encrypt_for_peer(share_value, participant_id)
            
            # Envoi via le r√©seau s√©curis√©
            await self._send_to_peer(participant_id, {
                "type": "dkg_share",
                "operation_id": operation_id,
                "from_node": self.node_id,
                "encrypted_share": encrypted_share.hex()
            })
    
    def _encrypt_for_peer(self, data: bytes, peer_id: int) -> bytes:
        """Chiffre des donn√©es pour un pair sp√©cifique"""
        # Simulation du chiffrement asym√©trique
        session_key = self.session_keys.get(peer_id, secrets.token_bytes(32))
        self.session_keys[peer_id] = session_key
        
        # AES-GCM avec la cl√© de session
        iv = secrets.token_bytes(12)
        cipher = Cipher(algorithms.AES(session_key), modes.GCM(iv), backend=default_backend())
        encryptor = cipher.encryptor()
        
        ciphertext = encryptor.update(data) + encryptor.finalize()
        
        return iv + encryptor.tag + ciphertext
    
    async def _send_to_peer(self, peer_id: int, message: Dict):
        """Envoie un message √† un pair"""
        # Simulation de l'envoi r√©seau
        if self.network_interface:
            await self.network_interface.send_message(peer_id, message)
        else:
            print(f"üì§ {self.node_id} ‚Üí {peer_id}: {message['type']}")
    
    async def _collect_dkg_shares(self, operation_id: str, participants: List[int]):
        """Collecte les parts DKG des autres participants"""
        # Simulation de la collecte
        await asyncio.sleep(1.0)  # Attente r√©seau simul√©e
        
        # En production, impl√©menter la logique de collecte r√©elle
        print(f"üì• N≈ìud {self.node_id}: Collecte des parts DKG pour {operation_id}")
    
    async def _finalize_dkg(self, operation_id: str, secret_term: int) -> Optional[bytes]:
        """Finalise la DKG et calcule la part finale"""
        # Simulation de la finalisation
        # En production, combiner toutes les parts re√ßues
        
        final_share_value = secret_term  # Simplification pour la d√©mo
        return final_share_value.to_bytes(32, 'big')
    
    async def participate_in_signature(self, operation_id: str, message_hash: bytes, 
                                     share_id: str, participants: List[int]) -> Optional[Dict]:
        """
        Participe √† une signature √† seuil
        """
        if self.node_id not in participants:
            return None
        
        print(f"‚úçÔ∏è  N≈ìud {self.node_id}: Signature TSS {operation_id}")
        
        try:
            # R√©cup√©ration de la part de cl√©
            share = self.secure_storage.retrieve_share(share_id)
            if not share:
                print(f"‚ùå Part introuvable: {share_id}")
                return None
            
            # Cr√©ation de l'op√©ration
            operation = MPCOperation(
                operation_id=operation_id,
                operation_type=OperationType.TSS_SIGNING,
                participants=set(participants),
                threshold=self.threshold,
                status="in_progress",
                created_at=time.time(),
                timeout=60.0,
                parameters={"message_hash": message_hash.hex(), "share_id": share_id}
            )
            
            self.active_operations[operation_id] = operation
            self.state = MPCNodeState.PARTICIPATING
            
            # G√©n√©ration de la contribution de signature
            signature_contribution = await self._generate_signature_contribution(
                share, message_hash, participants
            )
            
            if signature_contribution:
                # G√©n√©ration ZKP de validit√©
                zkp_proof = await self._generate_contribution_proof(
                    signature_contribution, share_id
                )
                
                result = {
                    "node_id": self.node_id,
                    "contribution": signature_contribution,
                    "zkp_proof": zkp_proof,
                    "timestamp": time.time()
                }
                
                operation.status = "completed"
                operation.result = result
                self.metrics["signatures_generated"] += 1
                self.metrics["operations_completed"] += 1
                
                print(f"‚úÖ Contribution signature g√©n√©r√©e: {operation_id}")
                return result
            
            return None
            
        except Exception as e:
            print(f"‚ùå Erreur signature TSS: {e}")
            if operation_id in self.active_operations:
                self.active_operations[operation_id].status = "failed"
            self.metrics["operations_failed"] += 1
            return None
        
        finally:
            self.state = MPCNodeState.READY
    
    async def _generate_signature_contribution(self, share: SecretShare, 
                                             message_hash: bytes, participants: List[int]) -> Optional[Dict]:
        """G√©n√®re la contribution de signature √† seuil"""
        try:
            # Conversion de la part en entier
            share_value = int.from_bytes(share.share_value, 'big')
            message_int = int.from_bytes(message_hash, 'big')
            
            # Simulation de l'ECDSA √† seuil
            # En production, utiliser un vrai protocole TSS
            
            # G√©n√©ration du nonce local
            k_local = secrets.randbelow(2**256)
            
            # Calcul de la contribution (simplifi√©)
            r_contribution = pow(k_local, 1, 2**256 - 2**32 - 977)  # Point R partiel
            s_contribution = (k_local + message_int * share_value) % (2**256 - 2**32 - 977)
            
            return {
                "r_part": r_contribution,
                "s_part": s_contribution,
                "participant_id": self.node_id
            }
            
        except Exception as e:
            print(f"‚ùå Erreur g√©n√©ration contribution: {e}")
            return None
    
    async def _generate_contribution_proof(self, contribution: Dict, share_id: str) -> Optional[Dict]:
        """G√©n√®re une preuve ZKP de validit√© de la contribution"""
        if not self.zkp_interface:
            return {"proof_type": "simulated", "valid": True}
        
        try:
            # Simulation de la g√©n√©ration de preuve ZKP
            proof_data = {
                "proof_type": "contribution_validity",
                "node_id": self.node_id,
                "share_id": share_id,
                "contribution_hash": hashlib.sha256(
                    json.dumps(contribution, sort_keys=True).encode()
                ).hexdigest(),
                "timestamp": time.time()
            }
            
            return proof_data
            
        except Exception as e:
            print(f"‚ùå Erreur g√©n√©ration preuve ZKP: {e}")
            return None
    
    async def _heartbeat_routine(self):
        """Routine de heartbeat pour surveillance de sant√©"""
        while self.state != MPCNodeState.OFFLINE:
            try:
                self.metrics["last_heartbeat"] = time.time()
                
                # V√©rification de la sant√© du n≈ìud
                health_status = self._check_node_health()
                
                if not health_status["healthy"]:
                    print(f"‚ö†Ô∏è  N≈ìud {self.node_id}: Probl√®me de sant√© d√©tect√©")
                    if health_status["critical"]:
                        self.state = MPCNodeState.RECOVERING
                
                await asyncio.sleep(30)  # Heartbeat toutes les 30 secondes
                
            except Exception as e:
                print(f"‚ùå Erreur heartbeat: {e}")
                await asyncio.sleep(5)
    
    def _check_node_health(self) -> Dict[str, Any]:
        """V√©rifie la sant√© du n≈ìud"""
        # V√©rifications de base
        memory_usage = len(self.active_operations)
        storage_health = len(self.secure_storage.shares) < 10000  # Limite arbitraire
        
        # V√©rification des op√©rations qui tra√Ænent
        current_time = time.time()
        stuck_operations = [
            op for op in self.active_operations.values()
            if current_time - op.created_at > op.timeout
        ]
        
        healthy = memory_usage < 100 and storage_health and len(stuck_operations) == 0
        critical = memory_usage > 500 or len(stuck_operations) > 10
        
        return {
            "healthy": healthy,
            "critical": critical,
            "memory_usage": memory_usage,
            "storage_health": storage_health,
            "stuck_operations": len(stuck_operations)
        }
    
    async def _security_monitoring(self):
        """Surveillance de s√©curit√© continue"""
        while self.state != MPCNodeState.OFFLINE:
            try:
                # V√©rification de l'int√©grit√© des parts stock√©es
                integrity_check = await self._verify_storage_integrity()
                
                # D√©tection d'activit√© suspecte
                suspicious_activity = self._detect_suspicious_activity()
                
                # Rotation automatique des cl√©s de session
                if self.security_config.auto_key_rotation:
                    await self._rotate_session_keys()
                
                if not integrity_check or suspicious_activity:
                    print(f"üö® N≈ìud {self.node_id}: Alerte de s√©curit√©")
                    # En production, d√©clencher des mesures de s√©curit√©
                
                await asyncio.sleep(300)  # V√©rification toutes les 5 minutes
                
            except Exception as e:
                print(f"‚ùå Erreur surveillance s√©curit√©: {e}")
                await asyncio.sleep(30)
    
    async def _verify_storage_integrity(self) -> bool:
        """V√©rifie l'int√©grit√© du stockage s√©curis√©"""
        try:
            # V√©rification de quelques parts au hasard
            share_ids = list(self.secure_storage.shares.keys())
            if not share_ids:
                return True
            
            # Test sur 10% des parts ou minimum 1
            test_count = max(1, len(share_ids) // 10)
            test_shares = secrets.SystemRandom().sample(share_ids, min(test_count, len(share_ids)))
            
            for share_id in test_shares:
                if not self.secure_storage._verify_integrity(share_id):
                    print(f"‚ùå Int√©grit√© compromise: {share_id}")
                    return False
            
            return True
            
        except Exception as e:
            print(f"‚ùå Erreur v√©rification int√©grit√©: {e}")
            return False
    
    def _detect_suspicious_activity(self) -> bool:
        """D√©tecte une activit√© suspecte"""
        current_time = time.time()
        
        # V√©rification du rate limiting
        for operation_type, timestamps in self.rate_limiter.items():
            # Nettoyage des anciens timestamps
            recent_timestamps = [t for t in timestamps if current_time - t < 3600]  # 1 heure
            self.rate_limiter[operation_type] = recent_timestamps
            
            # D√©tection de surcharge
            if len(recent_timestamps) > self.security_config.max_operations_per_hour:
                print(f"‚ö†Ô∏è  Taux d'op√©rations suspect pour {operation_type}")
                return True
        
        return False
    
    async def _rotate_session_keys(self):
        """Rotation des cl√©s de session"""
        try:
            # Rotation seulement si n√©cessaire
            current_time = time.time()
            last_rotation = getattr(self, '_last_key_rotation', 0)
            
            if current_time - last_rotation > self.security_config.key_rotation_interval:
                # G√©n√©ration de nouvelles cl√©s de session
                new_session_keys = {}
                for peer_id in self.trusted_peers:
                    new_session_keys[peer_id] = secrets.token_bytes(32)
                
                self.session_keys = new_session_keys
                self._last_key_rotation = current_time
                
                print(f"üîÑ N≈ìud {self.node_id}: Rotation des cl√©s de session")
                
        except Exception as e:
            print(f"‚ùå Erreur rotation cl√©s: {e}")
    
    async def _cleanup_routine(self):
        """Routine de nettoyage p√©riodique"""
        while self.state != MPCNodeState.OFFLINE:
            try:
                await asyncio.sleep(1800)  # Toutes les 30 minutes
                
                # Nettoyage des op√©rations termin√©es anciennes
                current_time = time.time()
                old_operations = [
                    op_id for op_id, op in self.active_operations.items()
                    if op.status in ["completed", "failed"] and current_time - op.created_at > 3600
                ]
                
                for op_id in old_operations:
                    await self._cleanup_operation_data(op_id)
                    del self.active_operations[op_id]
                
                # Limitation de l'historique
                if len(self.operation_history) > 1000:
                    self.operation_history = self.operation_history[-500:]
                
                print(f"üßπ N≈ìud {self.node_id}: Nettoyage - {len(old_operations)} op√©rations supprim√©es")
                
            except Exception as e:
                print(f"‚ùå Erreur nettoyage: {e}")
    
    async def _cleanup_operation_data(self, operation_id: str):
        """Nettoie les donn√©es temporaires d'une op√©ration"""
        # Ajout √† l'historique
        if operation_id not in self.operation_history:
            self.operation_history.append(operation_id)
        
        # Nettoyage s√©curis√© des donn√©es sensibles temporaires
        # En production, √©crasement s√©curis√© de la m√©moire
    
    def get_node_status(self) -> Dict[str, Any]:
        """Retourne le statut complet du n≈ìud"""
        current_time = time.time()
        uptime = current_time - self.metrics["uptime_start"]
        
        return {
            "node_id": self.node_id,
            "state": self.state.value,
            "uptime_seconds": uptime,
            "metrics": self.metrics.copy(),
            "active_operations": len(self.active_operations),
            "stored_shares": len(self.secure_storage.shares),
            "trusted_peers": len(self.trusted_peers),
            "last_heartbeat": self.metrics["last_heartbeat"],
            "security_config": {
                "attestation_enabled": self.security_config.attestation_enabled,
                "auto_key_rotation": self.security_config.auto_key_rotation,
                "max_operations_per_hour": self.security_config.max_operations_per_hour
            }
        }

# Exemple d'utilisation
if __name__ == "__main__":
    async def test_mpc_node():
        # Cr√©ation de 5 n≈ìuds MPC
        nodes = []
        for i in range(5):
            node = MPCNode(i, total_nodes=5, threshold=3)
            nodes.append(node)
        
        print("üß™ Test des n≈ìuds MPC")
        
        # Simulation d'une DKG
        participants = [0, 1, 2, 3]  # 4 participants
        operation_id = "dkg_test_001"
        
        try:
            # D√©marrage simultan√© de la DKG sur tous les n≈ìuds participants
            dkg_tasks = []
            for node in nodes[:4]:  # Seulement les 4 premiers
                task = asyncio.create_task(
                    node.participate_in_dkg(operation_id, participants)
                )
                dkg_tasks.append(task)
            
            # Attendre que tous terminent
            results = await asyncio.gather(*dkg_tasks, return_exceptions=True)
            
            successful_nodes = sum(1 for r in results if r is True)
            print(f"DKG r√©ussie sur {successful_nodes}/{len(participants)} n≈ìuds")
            
            # Affichage des statuts
            for i, node in enumerate(nodes[:4]):
                status = node.get_node_status()
                print(f"  N≈ìud {i}: {status['state']}, "
                      f"Parts: {status['stored_shares']}, "
                      f"Op√©rations: {status['metrics']['operations_completed']}")
                
        except Exception as e:
            print(f"‚ùå Erreur test: {e}")
    
    # Ex√©cution du test
    asyncio.run(test_mpc_node())
